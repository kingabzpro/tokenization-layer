# Tokenization Layer
This is a concept for a tokenization algorithm that is a neural network layer, training as part of a model trying to solve some NLP task, to make tokens that are best for the task. Read more [here](https://deepnote.com/@martin-molnar/New-Tokenization-Algorithm-lc4vP_CSTYa47GWynT0MeQ).
